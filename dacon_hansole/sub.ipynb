{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poetry 환경 구축 및 모듈 설치\n",
    "\n",
    "```\n",
    "poetry new \"project name\" -> Ex) Poetry add sutdy\n",
    "poetry install\n",
    "poetry env info 에 나오는 Executable 경로 가져오기기\n",
    "```\n",
    "1. Vscode 일 경우\n",
    "\n",
    "Ctrl + shift + P\n",
    "select interpreter\n",
    "+ 가상환경 만들기\n",
    "Executable의 경로 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following packages are already present in the pyproject.toml and will be skipped:\n",
      "\n",
      "  - pandas\n",
      "  - langchain\n",
      "  - transformers\n",
      "  - torch\n",
      "  - langchain_community\n",
      "\n",
      "If you want to update it to the latest compatible version, you can use `poetry update package`.\n",
      "If you prefer to upgrade it to the latest available version, you can use `poetry add package@latest`.\n",
      "\n",
      "Nothing to add.\n"
     ]
    }
   ],
   "source": [
    "# 필요 모듈 설치\n",
    "!poetry add pandas langchain transformers torch langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모듈 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "create_retrieval_chain(\n",
      "    retriever: \u001b[33m'Union[BaseRetriever, Runnable[dict, RetrieverOutput]]'\u001b[39m,\n",
      "    combine_docs_chain: \u001b[33m'Runnable[Dict[str, Any], str]'\u001b[39m,\n",
      ") -> \u001b[33m'Runnable'\u001b[39m\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Create retrieval chain that retrieves documents and then passes them on.\n",
      "\n",
      "Args:\n",
      "    retriever: Retriever-like object that returns list of documents. Should\n",
      "        either be a subclass of BaseRetriever or a Runnable that returns\n",
      "        a list of documents. If a subclass of BaseRetriever, then it\n",
      "        is expected that an `input` key be passed in - this is what\n",
      "        is will be used to pass into the retriever. If this is NOT a\n",
      "        subclass of BaseRetriever, then all the inputs will be passed\n",
      "        into this runnable, meaning that runnable should take a dictionary\n",
      "        as input.\n",
      "    combine_docs_chain: Runnable that takes inputs and produces a string output.\n",
      "        The inputs to this will be any original inputs to this chain, a new\n",
      "        context key with the retrieved documents, and chat_history (if not present\n",
      "        in the inputs) with a value of `[]` (to easily enable conversational\n",
      "        retrieval.\n",
      "\n",
      "Returns:\n",
      "    An LCEL Runnable. The Runnable return is a dictionary containing at the very\n",
      "    least a `context` and `answer` key.\n",
      "\n",
      "Example:\n",
      "    .. code-block:: python\n",
      "\n",
      "        # pip install -U langchain langchain-community\n",
      "\n",
      "        from langchain_community.chat_models import ChatOpenAI\n",
      "        from langchain.chains.combine_documents import create_stuff_documents_chain\n",
      "        from langchain.chains import create_retrieval_chain\n",
      "        from langchain import hub\n",
      "\n",
      "        retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
      "        llm = ChatOpenAI()\n",
      "        retriever = ...\n",
      "        combine_docs_chain = create_stuff_documents_chain(\n",
      "            llm, retrieval_qa_chat_prompt\n",
      "        )\n",
      "        retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
      "\n",
      "        retrieval_chain.invoke({\"input\": \"...\"})\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\keyha\\appdata\\local\\pypoetry\\cache\\virtualenvs\\dacon-hansole-rsn30irf-py3.11\\lib\\site-packages\\langchain\\chains\\retrieval.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "create_retrieval_chain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 가져오기 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>발생일시</th>\n",
       "      <th>사고인지 시간</th>\n",
       "      <th>날씨</th>\n",
       "      <th>기온</th>\n",
       "      <th>습도</th>\n",
       "      <th>공사종류</th>\n",
       "      <th>연면적</th>\n",
       "      <th>층 정보</th>\n",
       "      <th>인적사고</th>\n",
       "      <th>물적사고</th>\n",
       "      <th>공종</th>\n",
       "      <th>사고객체</th>\n",
       "      <th>작업프로세스</th>\n",
       "      <th>장소</th>\n",
       "      <th>부위</th>\n",
       "      <th>사고원인</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>2024-06-03 오전 09:39</td>\n",
       "      <td>정규작업 -</td>\n",
       "      <td>맑음</td>\n",
       "      <td>27℃</td>\n",
       "      <td>53%</td>\n",
       "      <td>건축 / 건축물 / 교정 및 군사시설</td>\n",
       "      <td>1,990.32㎡</td>\n",
       "      <td>지상 1층, 지하 0층</td>\n",
       "      <td>부딪힘</td>\n",
       "      <td>전도</td>\n",
       "      <td>건축 &gt; 철근콘크리트공사</td>\n",
       "      <td>건설기계 &gt; 콘크리트펌프</td>\n",
       "      <td>타설작업</td>\n",
       "      <td>교정 및 군사시설 / 외부</td>\n",
       "      <td>콘크리트펌프 / 바닥</td>\n",
       "      <td>펌프카 아웃트리거 바닥 고임목을 3단으로 보강 했음에도, 지반 침하(아웃트리거 우측...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>2024-02-15 오전 09:00</td>\n",
       "      <td>정규작업 -</td>\n",
       "      <td>맑음</td>\n",
       "      <td>5℃</td>\n",
       "      <td>71%</td>\n",
       "      <td>건축 / 건축물 / 운수시설</td>\n",
       "      <td>349,895㎡</td>\n",
       "      <td>지상 5층, 지하 2층</td>\n",
       "      <td>절단, 베임</td>\n",
       "      <td>없음</td>\n",
       "      <td>건축 &gt; 수장공사</td>\n",
       "      <td>건설공구 &gt; 공구류</td>\n",
       "      <td>절단작업</td>\n",
       "      <td>운수시설 / 내부</td>\n",
       "      <td>공구류 / 핸드그라인더</td>\n",
       "      <td>작업자의 불안전한 행동(숫돌 측면 사용) 및 보안면 미 착용</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>2024-02-01 오전 09:30</td>\n",
       "      <td>작업 전 -</td>\n",
       "      <td>흐림</td>\n",
       "      <td>5℃</td>\n",
       "      <td>58%</td>\n",
       "      <td>건축 / 건축물 / 공동주택</td>\n",
       "      <td>171,198㎡</td>\n",
       "      <td>지상 27층, 지하 2층</td>\n",
       "      <td>떨어짐(2미터 미만)</td>\n",
       "      <td>없음</td>\n",
       "      <td>건축 &gt; 미장공사</td>\n",
       "      <td>기타 &gt; 기타</td>\n",
       "      <td>이동</td>\n",
       "      <td>공동주택 / 내부</td>\n",
       "      <td>기타 / 바닥</td>\n",
       "      <td>작업자가 작업을 위해 이동 중 전방을 주시하지 않아 발을 헛디뎌 계단에서 굴러 넘어짐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>2024-02-06 오후 05:00</td>\n",
       "      <td>정규작업 -</td>\n",
       "      <td>맑음</td>\n",
       "      <td>1℃</td>\n",
       "      <td>87%</td>\n",
       "      <td>건축 / 건축물 / 공동주택</td>\n",
       "      <td>123,540.98㎡</td>\n",
       "      <td>지상 2층, 지하 35층</td>\n",
       "      <td>넘어짐(물체에 걸림)</td>\n",
       "      <td>없음</td>\n",
       "      <td>건축 &gt; 조적공사</td>\n",
       "      <td>건설자재 &gt; 자재</td>\n",
       "      <td>기타</td>\n",
       "      <td>공동주택 / 102동 801호 세대 내부</td>\n",
       "      <td>자재 / 말비계(H:720mm)</td>\n",
       "      <td>작업 발판 위 벽돌 잔재를 밟고 넘어짐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>2024-06-03 오전 11:35</td>\n",
       "      <td>기타 -</td>\n",
       "      <td>흐림</td>\n",
       "      <td>22℃</td>\n",
       "      <td>60%</td>\n",
       "      <td>토목 / 교량 / 도로교량</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>떨어짐(2미터 미만)</td>\n",
       "      <td>없음</td>\n",
       "      <td>토목 &gt; 교량공사</td>\n",
       "      <td>기타 &gt; 기타</td>\n",
       "      <td>해체작업</td>\n",
       "      <td>도로교량 / 외부</td>\n",
       "      <td>기타 / 바닥</td>\n",
       "      <td>점심식사를 위한 이동시 작업자 부주의로 인한 추락사고 발생</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                 발생일시 사고인지 시간  날씨   기온   습도                  공사종류  \\\n",
       "0  TEST_000  2024-06-03 오전 09:39  정규작업 -  맑음  27℃  53%  건축 / 건축물 / 교정 및 군사시설   \n",
       "1  TEST_001  2024-02-15 오전 09:00  정규작업 -  맑음   5℃  71%       건축 / 건축물 / 운수시설   \n",
       "2  TEST_002  2024-02-01 오전 09:30  작업 전 -  흐림   5℃  58%       건축 / 건축물 / 공동주택   \n",
       "3  TEST_003  2024-02-06 오후 05:00  정규작업 -  맑음   1℃  87%       건축 / 건축물 / 공동주택   \n",
       "4  TEST_004  2024-06-03 오전 11:35    기타 -  흐림  22℃  60%        토목 / 교량 / 도로교량   \n",
       "\n",
       "           연면적           층 정보         인적사고 물적사고             공종           사고객체  \\\n",
       "0    1,990.32㎡   지상 1층, 지하 0층          부딪힘   전도  건축 > 철근콘크리트공사  건설기계 > 콘크리트펌프   \n",
       "1     349,895㎡   지상 5층, 지하 2층       절단, 베임   없음      건축 > 수장공사     건설공구 > 공구류   \n",
       "2     171,198㎡  지상 27층, 지하 2층  떨어짐(2미터 미만)   없음      건축 > 미장공사        기타 > 기타   \n",
       "3  123,540.98㎡  지상 2층, 지하 35층  넘어짐(물체에 걸림)   없음      건축 > 조적공사      건설자재 > 자재   \n",
       "4            -              -  떨어짐(2미터 미만)   없음      토목 > 교량공사        기타 > 기타   \n",
       "\n",
       "  작업프로세스                      장소                 부위  \\\n",
       "0   타설작업          교정 및 군사시설 / 외부        콘크리트펌프 / 바닥   \n",
       "1   절단작업               운수시설 / 내부       공구류 / 핸드그라인더   \n",
       "2     이동               공동주택 / 내부            기타 / 바닥   \n",
       "3     기타  공동주택 / 102동 801호 세대 내부  자재 / 말비계(H:720mm)   \n",
       "4   해체작업               도로교량 / 외부            기타 / 바닥   \n",
       "\n",
       "                                                사고원인  \n",
       "0  펌프카 아웃트리거 바닥 고임목을 3단으로 보강 했음에도, 지반 침하(아웃트리거 우측...  \n",
       "1                  작업자의 불안전한 행동(숫돌 측면 사용) 및 보안면 미 착용  \n",
       "2    작업자가 작업을 위해 이동 중 전방을 주시하지 않아 발을 헛디뎌 계단에서 굴러 넘어짐  \n",
       "3                              작업 발판 위 벽돌 잔재를 밟고 넘어짐  \n",
       "4                   점심식사를 위한 이동시 작업자 부주의로 인한 추락사고 발생  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['공사종류(대분류)'] = train['공사종류'].str.split('/').str[0]\n",
    "train['공사종류(중분류)'] = train['공사종류'].str.split('/').str[1]\n",
    "train['공종(대분류)'] = train['공종'].str.split('>').str[0]\n",
    "train['공종(중분류)'] = train['공종'].str.split('>').str[1]\n",
    "train['사고객체(대분류)'] = train['사고객체'].str.split('>').str[0]\n",
    "train['사고객체(중분류)'] = train['사고객체'].str.split('>').str[1]\n",
    "\n",
    "test['공사종류(대분류)'] = test['공사종류'].str.split('/').str[0]\n",
    "test['공사종류(중분류)'] = test['공사종류'].str.split('/').str[1]\n",
    "test['공종(대분류)'] = test['공종'].str.split('>').str[0]\n",
    "test['공종(중분류)'] = test['공종'].str.split('>').str[1]\n",
    "test['사고객체(대분류)'] = test['사고객체'].str.split('>').str[0]\n",
    "test['사고객체(중분류)'] = test['사고객체'].str.split('>').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', '발생일시', '사고인지 시간', '날씨', '기온', '습도', '공사종류', '연면적', '층 정보',\n",
       "       '인적사고', '물적사고', '공종', '사고객체', '작업프로세스', '장소', '부위', '사고원인',\n",
       "       '재발방지대책 및 향후조치계획', '공사종류(대분류)', '공사종류(중분류)', '공종(대분류)', '공종(중분류)',\n",
       "       '사고객체(대분류)', '사고객체(중분류)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.apply(\n",
    "#     lambda row : print(row)\n",
    "# )\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 통합 생성\n",
    "combined_training_data = train.apply(\n",
    "    lambda row : {\n",
    "        \"question\" : (\n",
    "            f\"공사종류 대분류 '{row['공사종류(대분류)']}', 중분류 '{row['공사종류(중분류)']}' 공사 중\"\n",
    "            f\"공종 대분류 '{row['공종(대분류)']}', 중분류 '{row['공종(중분류)']}' 작업에서\"\n",
    "            f\"사고객체 '{row['사고객체(대분류)']}', '중분류 : {row['사고객체(중분류)']}'와 관련된 사고가 발생했습니다.\"\n",
    "            f\"작업프로세스는 '{row['작업프로세스']}'이며, 사고 원인은 '{row['사고원인']}' 입니다.\"\n",
    "            f\"재발 방지 대책 및 향후 조치 계획은 무엇인가요?\"\n",
    "        ),\n",
    "        \"answer\" : row[\"재발방지대책 및 향후조치계획\"]\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "combined_training_data = pd.DataFrame(list(combined_training_data))\n",
    "\n",
    "combined_test_data = test.apply(\n",
    "    lambda row : {\n",
    "        \"question\" : (\n",
    "            f\"공사종류 대분류 '{row['공사종류(대분류)']}', 중분류 '{row['공사종류(중분류)']}' 공사 중\"\n",
    "            f\"공종 대분류 '{row['공종(대분류)']}', 중분류 '{row['공종(중분류)']}' 작업에서\"\n",
    "            f\"사고객체 '{row['사고객체(대분류)']}', '중분류 : {row['사고객체(중분류)']}'와 관련된 사고가 발생했습니다.\"\n",
    "            f\"작업프로세스는 '{row['작업프로세스']}'이며, 사고 원인은 '{row['사고원인']}' 입니다.\"\n",
    "            f\"재발 방지 대책 및 향후 조치 계획은 무엇인가요?\"\n",
    "        ),\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "combined_test_data = pd.DataFrame(list(combined_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following packages are already present in the pyproject.toml and will be skipped:\n",
      "\n",
      "  - bitsandbytes\n",
      "\n",
      "If you want to update it to the latest compatible version, you can use `poetry update package`.\n",
      "If you prefer to upgrade it to the latest available version, you can use `poetry add package@latest`.\n",
      "\n",
      "\n",
      "Updating dependencies\n",
      "Resolving dependencies...\n",
      "\n",
      "No dependencies to install or update\n"
     ]
    }
   ],
   "source": [
    "# !poetry add bitsandbytes accelerate>=0.26.0\n",
    "\n",
    "!poetry add accelerate==0.26.0 bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m bnb_config = BitsAndBytesConfig(\n\u001b[32m      2\u001b[39m     load_in_4bit=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      3\u001b[39m     bnb_4bit_use_double_quant=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      4\u001b[39m     bnb_4bit_quant_type=\u001b[33m\"\u001b[39m\u001b[33mnf4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     bnb_4bit_compute_dtype=torch.float32\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m model_id = \u001b[33m\"\u001b[39m\u001b[33mNCSOFT/Llama-VARCO-8B-Instruct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbnb_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\keyha\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\dacon-hansole-rSN30IrF-py3.11\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m    563\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    568\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    570\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\keyha\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\dacon-hansole-rSN30IrF-py3.11\\Lib\\site-packages\\transformers\\modeling_utils.py:262\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    260\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    264\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\keyha\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\dacon-hansole-rSN30IrF-py3.11\\Lib\\site-packages\\transformers\\modeling_utils.py:3698\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   3695\u001b[39m     hf_quantizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3697\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3698\u001b[39m     \u001b[43mhf_quantizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3704\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3705\u001b[39m     torch_dtype = hf_quantizer.update_torch_dtype(torch_dtype)\n\u001b[32m   3706\u001b[39m     device_map = hf_quantizer.update_device_map(device_map)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\keyha\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\dacon-hansole-rSN30IrF-py3.11\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py:83\u001b[39m, in \u001b[36mBnb4BitHfQuantizer.validate_environment\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_multi_backend_available\n\u001b[32m     82\u001b[39m bnb_multibackend_is_enabled = is_bitsandbytes_multi_backend_available()\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[43mvalidate_bnb_backend_availability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mfrom_tf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mfrom_flax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     87\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m sure the weights are in PyTorch format.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\keyha\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\dacon-hansole-rSN30IrF-py3.11\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:559\u001b[39m, in \u001b[36mvalidate_bnb_backend_availability\u001b[39m\u001b[34m(raise_exception)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_bitsandbytes_multi_backend_available():\n\u001b[32m    558\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _validate_bnb_multi_backend_availability(raise_exception)\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_validate_bnb_cuda_backend_availability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\keyha\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\dacon-hansole-rSN30IrF-py3.11\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:537\u001b[39m, in \u001b[36m_validate_bnb_cuda_backend_availability\u001b[39m\u001b[34m(raise_exception)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m raise_exception:\n\u001b[32m    536\u001b[39m     logger.error(log_msg)\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(log_msg)\n\u001b[32m    539\u001b[39m logger.warning(log_msg)\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend"
     ]
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float32\n",
    ")\n",
    "\n",
    "model_id = \"NCSOFT/Llama-VARCO-8B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon-hansole-rSN30IrF-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
